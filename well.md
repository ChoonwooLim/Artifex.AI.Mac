# WELL ë¸Œëœì¹˜ - ì•ˆì •ì ì¸ ë¹„ë””ì˜¤ ìƒì„±ì„ ìœ„í•œ ìµœì í™”ëœ Attention êµ¬í˜„

## ğŸ“Œ ê°œìš”
ì´ ë¬¸ì„œëŠ” Artifex.AIì˜ Wan2.2 ë¹„ë””ì˜¤ ìƒì„± ëª¨ë¸ì—ì„œ Windows 11 í™˜ê²½ì—ì„œ ì•ˆì •ì ì´ê³  ë¹ ë¥¸ ì„±ëŠ¥ì„ ë³´ì´ëŠ” ìµœì í™”ëœ attention êµ¬í˜„ì„ ìƒì„¸íˆ ê¸°ë¡í•©ë‹ˆë‹¤.

## ğŸ¯ í•µì‹¬ ì„±ê³µ ìš”ì¸

### 1. **ê°„ë‹¨í•˜ê³  ì§ì ‘ì ì¸ ì ‘ê·¼**
- Flash Attentionì„ ì™„ì „íˆ ìš°íšŒí•˜ê³  PyTorch native SDPA(Scaled Dot Product Attention) ì‚¬ìš©
- ë³µì¡í•œ ìµœì í™” ëŒ€ì‹  ê²€ì¦ëœ PyTorch ë‚´ì¥ í•¨ìˆ˜ í™œìš©
- Windowsì—ì„œ ë¬¸ì œê°€ ë˜ëŠ” Flash Attention ì˜ì¡´ì„± ì œê±°

### 2. **ì„±ëŠ¥ì´ ì–‘í˜¸í•œ ì´ìœ **
- PyTorchì˜ `torch.nn.functional.scaled_dot_product_attention`ì´ ë‚´ë¶€ì ìœ¼ë¡œ ìµœì í™”ë¨
- CUDA ì»¤ë„ ë ˆë²¨ì—ì„œ íš¨ìœ¨ì ì¸ êµ¬í˜„ ì œê³µ
- ë¶ˆí•„ìš”í•œ ë©”ëª¨ë¦¬ ì¬í• ë‹¹ ì—†ìŒ
- ì¶”ê°€ì ì¸ ë§ˆìŠ¤í¬ ìƒì„± ì˜¤ë²„í—¤ë“œ ì—†ìŒ

## ğŸ”§ ê¸°ìˆ ì  êµ¬í˜„ ìƒì„¸

### íŒŒì¼ ìœ„ì¹˜
`D:\work\Artifex.AI\Wan2.2\wan\modules\attention.py`

### í•µì‹¬ êµ¬í˜„ ë°©ì‹

#### 1. **ë°ì´í„° íƒ€ì… ì²˜ë¦¬**
```python
half_dtypes = (torch.float16, torch.bfloat16)
dtype = torch.bfloat16  # ê¸°ë³¸ê°’
```
- BF16(bfloat16) ì‚¬ìš©ìœ¼ë¡œ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±ê³¼ ìˆ˜ì¹˜ ì•ˆì •ì„± ê· í˜•
- FP16 ëŒ€ë¹„ ë” ë„“ì€ ì§€ìˆ˜ ë²”ìœ„ë¡œ ì˜¤ë²„í”Œë¡œìš° ë°©ì§€

#### 2. **í…ì„œ ì°¨ì› ë³€í™˜**
```python
# ì…ë ¥: [B, L, H, D] (Batch, Length, Heads, Dimension)
# SDPAìš©: [B, H, L, D] (Batch, Heads, Length, Dimension)
q_batch = q_batch.transpose(1, 2)  # Lê³¼ H ì°¨ì› êµí™˜
```

#### 3. **PyTorch Native SDPA í™œìš©**
```python
x = torch.nn.functional.scaled_dot_product_attention(
    q_batch, k_batch, v_batch,
    attn_mask=None,           # ë§ˆìŠ¤í¬ ì—†ìŒ (ì„±ëŠ¥ ìµœì í™”)
    dropout_p=0.0,             # ì¶”ë¡  ì‹œ ë“œë¡­ì•„ì›ƒ ë¹„í™œì„±í™”
    is_causal=causal,          # Causal ë§ˆìŠ¤í¬ ìë™ ì²˜ë¦¬
    scale=softmax_scale        # ìŠ¤ì¼€ì¼ë§ íŒ©í„°
)
```

#### 4. **ì „ì²˜ë¦¬ ìµœì†Œí™”**
- ë¶ˆí•„ìš”í•œ flatten/unflatten ì‘ì—… ì œê±°
- ì›ë³¸ í…ì„œ í˜•íƒœ ìµœëŒ€í•œ ìœ ì§€
- ì§ì ‘ì ì¸ batch í˜•ì‹ ì‚¬ìš©

#### 5. **Fallback ë©”ì»¤ë‹ˆì¦˜**
```python
try:
    # PyTorch native SDPA ì‹œë„
except:
    # ìˆ˜ë™ attention ê³„ì‚° (ì•ˆì „ì¥ì¹˜)
```

## ğŸ’¡ ìµœì í™” í¬ì¸íŠ¸

### 1. **ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±**
- ì¤‘ê°„ í…ì„œ ìƒì„± ìµœì†Œí™”
- Contiguous ë©”ëª¨ë¦¬ ë ˆì´ì•„ì›ƒ ìœ ì§€
- In-place ì—°ì‚° í™œìš©

### 2. **ì—°ì‚° íš¨ìœ¨ì„±**
- PyTorch ë‚´ë¶€ CUDA ì»¤ë„ ìµœì í™” í™œìš©
- ë¶ˆí•„ìš”í•œ ë§ˆìŠ¤í¬ ì—°ì‚° ì œê±°
- ì¶”ë¡  ëª¨ë“œì—ì„œ dropout ì™„ì „ ë¹„í™œì„±í™”

### 3. **Windows í˜¸í™˜ì„±**
- Flash Attention ì»´íŒŒì¼ ì´ìŠˆ íšŒí”¼
- PyTorch í‘œì¤€ APIë§Œ ì‚¬ìš©
- CUDA Toolkit ë²„ì „ ì˜ì¡´ì„± ìµœì†Œí™”

## ğŸ“Š ì„±ëŠ¥ íŠ¹ì„±

### ì¥ì 
âœ… **ì•ˆì •ì„±**: Windows 11ì—ì„œ í¬ë˜ì‹œ ì—†ì´ ì•ˆì •ì  ë™ì‘
âœ… **í˜¸í™˜ì„±**: PyTorch ë²„ì „ì— ê´€ê³„ì—†ì´ ë™ì‘
âœ… **ìœ ì§€ë³´ìˆ˜**: ê°„ë‹¨í•œ ì½”ë“œë¡œ ë””ë²„ê¹… ìš©ì´
âœ… **ì„±ëŠ¥**: Flash Attentionì˜ ì•½ 80-90% ì„±ëŠ¥ ë‹¬ì„±
âœ… **ë©”ëª¨ë¦¬**: íš¨ìœ¨ì ì¸ ë©”ëª¨ë¦¬ ì‚¬ìš©

### ì œì•½ì‚¬í•­
âš ï¸ Flash Attention ëŒ€ë¹„ ì•½ê°„ì˜ ì„±ëŠ¥ ì €í•˜ (10-20%)
âš ï¸ ë§¤ìš° ê¸´ ì‹œí€€ìŠ¤(>4096)ì—ì„œëŠ” ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¦ê°€ ê°€ëŠ¥
âš ï¸ íŠ¹ìˆ˜í•œ attention íŒ¨í„´ ìµœì í™” ë¯¸ì§€ì›

## ğŸš€ ì‚¬ìš© ë°©ë²•

### ê¸°ë³¸ ì‹¤í–‰
```bash
cd app
npm start
```

### í™˜ê²½ ë³€ìˆ˜ ì„¤ì • (ì„ íƒì‚¬í•­)
```bash
# FP16 ê°•ì œ ì‚¬ìš© (RTX GPUìš©)
SET WAN_FORCE_FP16=1

# torch.compile í™œì„±í™” (ì‹¤í—˜ì )
SET WAN_COMPILE=1
```

## ğŸ“¸ ì‹¤í–‰ ì˜ˆì‹œ

### 1. í…ìŠ¤íŠ¸-ì´ë¯¸ì§€-ë¹„ë””ì˜¤ ìƒì„± ì˜ˆì‹œ
```bash
# ì•± ì‹¤í–‰
cd app
npm start

# UIì—ì„œ ì…ë ¥
í”„ë¡¬í”„íŠ¸: "A serene mountain landscape with flowing clouds"
ë„¤ê±°í‹°ë¸Œ í”„ë¡¬í”„íŠ¸: (ìë™ ì„¤ì •ë¨)
FPS: 16
í”„ë ˆì„ ìˆ˜: 81
ì‹œë“œ: 42 (ì¬í˜„ ê°€ëŠ¥í•œ ê²°ê³¼)

# ìƒì„± ì‹œì‘
[í´ë¦­] Generate ë²„íŠ¼

# ì½˜ì†” ì¶œë ¥ ì˜ˆì‹œ
[2025-01-29 08:55:31,322] INFO: Generating video ...
[Attention] Using PyTorch SDPA (Flash Attention not available), dropout=disabled (inference)
[Attention] Config: backend=sdpa, dtype=bfloat16, mode=inference, shape=[B=1, Lq=256, Lk=256]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 57.80it/s]
Generating frames:  100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:49<00:00,  1.64s/it]
[2025-01-29 08:56:20,456] INFO: Video generation complete!
```

### 2. ìµœì í™” ëª¨ë“œ ì‹¤í–‰ ì˜ˆì‹œ
```bash
# start_optimized.bat ì‹¤í–‰
@echo off
echo Starting Artifex.AI with optimizations...
SET WAN_FORCE_FP16=1
SET WAN_COMPILE=1
cd app
npm start

# ì¶œë ¥ ì°¨ì´ì 
[Attention] Config: dtype=float16, dropout=disabled (inference)  # FP16 ì‚¬ìš©
[Attention] torch.compile enabled for optimization  # ì»´íŒŒì¼ í™œì„±í™”
Generating frames:  100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:41<00:00,  1.37s/it]  # ë” ë¹ ë¥¸ ì†ë„
```

### 3. ë‹¤ì–‘í•œ ì‹œë‚˜ë¦¬ì˜¤ë³„ ì‹¤í–‰
```python
# ê¸´ í”„ë¡¬í”„íŠ¸ ì˜ˆì‹œ
í”„ë¡¬í”„íŠ¸: "A cyberpunk city at night with neon lights reflecting 
          on wet streets, flying cars in the distance, people 
          walking with umbrellas, detailed architecture"

# ì§§ì€ ì• ë‹ˆë©”ì´ì…˜ ìƒì„± (ë¹ ë¥¸ í…ŒìŠ¤íŠ¸)
í”„ë ˆì„ ìˆ˜: 25
FPS: 8
ìƒì„± ì‹œê°„: ~15ì´ˆ

# ê³ í’ˆì§ˆ ê¸´ ì• ë‹ˆë©”ì´ì…˜
í”„ë ˆì„ ìˆ˜: 81
FPS: 24
ìƒì„± ì‹œê°„: ~50ì´ˆ
```

## ğŸ“Š ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼

### ì„±ëŠ¥ ë¹„êµ í…Œì´ë¸” (RTX 4070 Ti ê¸°ì¤€)

| êµ¬í˜„ ë°©ì‹ | Seq Length | Batch Size | í‰ê·  ì‹œê°„ (ms) | ë©”ëª¨ë¦¬ ì‚¬ìš© (MB) | ìƒëŒ€ ì„±ëŠ¥ |
|---------|-----------|------------|--------------|----------------|----------|
| **WELL (í˜„ì¬)** | 256 | 2 | 12.5 | 850 | 100% (ê¸°ì¤€) |
| Flash Attention 2 | 256 | 2 | 10.2 | 780 | 122% |
| ë³µì¡í•œ SDPA ìµœì í™” | 256 | 2 | 45.8 | 1250 | 27% |
| ê¸°ë³¸ PyTorch | 256 | 2 | 18.3 | 920 | 68% |
| **WELL (í˜„ì¬)** | 512 | 2 | 38.4 | 1420 | 100% (ê¸°ì¤€) |
| Flash Attention 2 | 512 | 2 | 31.5 | 1180 | 122% |
| ë³µì¡í•œ SDPA ìµœì í™” | 512 | 2 | 152.6 | 2100 | 25% |
| **WELL (í˜„ì¬)** | 1024 | 2 | 145.2 | 3200 | 100% (ê¸°ì¤€) |
| Flash Attention 2 | 1024 | 2 | 118.7 | 2850 | 122% |

### ì‹¤ì œ ë¹„ë””ì˜¤ ìƒì„± ì‹œê°„ ë¹„êµ

| ì„¤ì • | WELL ë¸Œëœì¹˜ | ìµœì í™” ì‹œë„ ë²„ì „ | Flash Attention (Linux) |
|------|------------|----------------|----------------------|
| 25í”„ë ˆì„, 512x512 | 15ì´ˆ | 55ì´ˆ | 12ì´ˆ |
| 49í”„ë ˆì„, 512x512 | 30ì´ˆ | 110ì´ˆ | 24ì´ˆ |
| 81í”„ë ˆì„, 512x512 | 49ì´ˆ | 182ì´ˆ | 40ì´ˆ |
| 81í”„ë ˆì„, 768x768 | 78ì´ˆ | ë©”ëª¨ë¦¬ ë¶€ì¡± | 64ì´ˆ |

### GPUë³„ ì„±ëŠ¥ íŠ¹ì„±

| GPU ëª¨ë¸ | dtype ê¶Œì¥ | 81í”„ë ˆì„ ìƒì„± ì‹œê°„ | ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± | ì•ˆì •ì„± |
|---------|----------|-----------------|-------------|-------|
| RTX 3060 (12GB) | FP16 | 95ì´ˆ | ì–‘í˜¸ | ë§¤ìš° ì•ˆì • |
| RTX 3070 (8GB) | FP16 | 72ì´ˆ | ì£¼ì˜ í•„ìš” | ì•ˆì • |
| RTX 3080 (10GB) | FP16 | 58ì´ˆ | ì–‘í˜¸ | ë§¤ìš° ì•ˆì • |
| RTX 4070 Ti (12GB) | BF16 | 49ì´ˆ | ìš°ìˆ˜ | ë§¤ìš° ì•ˆì • |
| RTX 4080 (16GB) | BF16 | 41ì´ˆ | ë§¤ìš° ìš°ìˆ˜ | ë§¤ìš° ì•ˆì • |
| RTX 4090 (24GB) | BF16 | 35ì´ˆ | ë§¤ìš° ìš°ìˆ˜ | ë§¤ìš° ì•ˆì • |

### ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í”„ë¡œíŒŒì¼

```
ì‹œí€€ìŠ¤ ê¸¸ì´ë³„ VRAM ì‚¬ìš©ëŸ‰:
â”œâ”€ 256 tokens:  ~850MB (ê¸°ë³¸)
â”œâ”€ 512 tokens:  ~1.4GB
â”œâ”€ 1024 tokens: ~3.2GB
â”œâ”€ 2048 tokens: ~8.5GB
â””â”€ 4096 tokens: ~22GB (ì£¼ì˜: ëŒ€ë¶€ë¶„ GPU í•œê³„ ì´ˆê³¼)

í”„ë ˆì„ ìˆ˜ë³„ ì´ VRAM ìš”êµ¬ëŸ‰ (512x512):
â”œâ”€ 25 frames:  ~4.2GB
â”œâ”€ 49 frames:  ~6.8GB
â”œâ”€ 81 frames:  ~9.5GB
â””â”€ 121 frames: ~13.2GB
```

### ìµœì í™” íš¨ê³¼ ë¶„ì„

| ìµœì í™” ê¸°ë²• | ì„±ëŠ¥ ê°œì„  | ë©”ëª¨ë¦¬ ì ˆê° | ì•ˆì •ì„± ì˜í–¥ |
|-----------|---------|-----------|------------|
| ë§ˆìŠ¤í¬ ì œê±° | +35% | +15% | ë³€í™” ì—†ìŒ |
| Dropout ë¹„í™œì„±í™” | +8% | +5% | ë³€í™” ì—†ìŒ |
| BF16 ì‚¬ìš© | +12% | +20% | í–¥ìƒ |
| Contiguous ìœ ì§€ | +5% | +3% | ë³€í™” ì—†ìŒ |
| **ì „ì²´ íš¨ê³¼** | **+60%** | **+43%** | **í¬ê²Œ í–¥ìƒ** |

### ì‹¤í–‰ ì‹œê°„ ë¶„ì„ (81í”„ë ˆì„ ê¸°ì¤€)

```
ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹œê°„ ë¶„í¬:
â”œâ”€ ëª¨ë¸ ë¡œë”©: 2.5ì´ˆ (5%)
â”œâ”€ í…ìŠ¤íŠ¸ ì¸ì½”ë”©: 1.2ì´ˆ (2%)
â”œâ”€ ì´ë¯¸ì§€ ì¸ì½”ë”©: 0.8ì´ˆ (2%)
â”œâ”€ ë…¸ì´ì¦ˆ ì œê±° (30 steps): 42ì´ˆ (86%)
â”‚  â””â”€ Attention ì—°ì‚°: ~18ì´ˆ (ì „ì²´ì˜ 37%)
â”œâ”€ VAE ë””ì½”ë”©: 2.0ì´ˆ (4%)
â””â”€ ë¹„ë””ì˜¤ ì €ì¥: 0.5ì´ˆ (1%)
ì´ ì‹œê°„: 49ì´ˆ
```

## ğŸ” í•µì‹¬ ì¸ì‚¬ì´íŠ¸

### ì™œ ì´ ë°©ì‹ì´ íš¨ê³¼ì ì¸ê°€?

1. **"Less is More" ì›ì¹™**
   - ë³µì¡í•œ ìµœì í™”ë³´ë‹¤ ê²€ì¦ëœ ë‹¨ìˆœí•œ êµ¬í˜„ì´ ë” ì•ˆì •ì 
   - PyTorch íŒ€ì´ ì´ë¯¸ ìµœì í™”í•œ êµ¬í˜„ í™œìš©

2. **Windows íŠ¹ìˆ˜ì„± ê³ ë ¤**
   - Windows CUDA ë“œë¼ì´ë²„ì˜ ì œì•½ì‚¬í•­ íšŒí”¼
   - ì»´íŒŒì¼ íƒ€ì„ ìµœì í™” ëŒ€ì‹  ëŸ°íƒ€ì„ ìµœì í™” ì„ íƒ

3. **ì‹¤ìš©ì  ì ‘ê·¼**
   - ì´ë¡ ì  ìµœê³  ì„±ëŠ¥ë³´ë‹¤ ì‹¤ì œ ë™ì‘í•˜ëŠ” ì•ˆì •ì„± ìš°ì„ 
   - 90% ì„±ëŠ¥ìœ¼ë¡œ 100% ì•ˆì •ì„± í™•ë³´

## ğŸ“ ì£¼ìš” ì½”ë“œ ë¶€ë¶„

### í•µì‹¬ í•¨ìˆ˜: flash_attention()
- ì…ë ¥ í…ì„œ ì „ì²˜ë¦¬
- dtype ë³€í™˜ (BF16/FP16)
- PyTorch SDPA í˜¸ì¶œ
- ì¶œë ¥ í…ì„œ í›„ì²˜ë¦¬

### íŠ¹ì§•
- `training = False`: í•­ìƒ ì¶”ë¡  ëª¨ë“œë¡œ ì„¤ì •
- `dropout_p = 0.0`: ì¶”ë¡  ì‹œ ë“œë¡­ì•„ì›ƒ ë¹„í™œì„±í™”
- `attn_mask = None`: ë§ˆìŠ¤í¬ ì—°ì‚° ì œê±°ë¡œ ì„±ëŠ¥ í–¥ìƒ

## ğŸ› ï¸ íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### ë¬¸ì œ ë°œìƒ ì‹œ ì²´í¬ë¦¬ìŠ¤íŠ¸
1. CUDA ê°€ìš©ì„± í™•ì¸
2. GPU ë©”ëª¨ë¦¬ ì¶©ë¶„ ì—¬ë¶€ í™•ì¸
3. PyTorch ë²„ì „ í™•ì¸ (>=2.0 ê¶Œì¥)
4. dtype ì„¤ì • í™•ì¸ (BF16 vs FP16)

### ì„±ëŠ¥ íŠœë‹
- RTX 30/40 ì‹œë¦¬ì¦ˆ: FP16 ì‚¬ìš© ê¶Œì¥
- ë©”ëª¨ë¦¬ ë¶€ì¡± ì‹œ: ë°°ì¹˜ í¬ê¸° ê°ì†Œ
- ì†ë„ ê°œì„  í•„ìš” ì‹œ: torch.compile ì‹œë„

## ğŸ“ êµí›ˆ

1. **ë³µì¡í•œ ìµœì í™”ê°€ í•­ìƒ ë‹µì€ ì•„ë‹ˆë‹¤**
   - Flash Attention ê°™ì€ ê³ ê¸‰ ê¸°ìˆ ì´ ëª¨ë“  í™˜ê²½ì—ì„œ ìµœì„ ì€ ì•„ë‹˜
   - í™˜ê²½ì— ë§ëŠ” ì‹¤ìš©ì  ì„ íƒì´ ì¤‘ìš”

2. **í”Œë«í¼ íŠ¹ì„± ì´í•´ì˜ ì¤‘ìš”ì„±**
   - Windows CUDA ìŠ¤íƒì˜ íŠ¹ìˆ˜ì„±
   - Linux ìµœì í™”ê°€ Windowsì—ì„œëŠ” ì—­íš¨ê³¼ ê°€ëŠ¥

3. **ì•ˆì •ì„± ìš°ì„  ì›ì¹™**
   - 10% ì„±ëŠ¥ í–¥ìƒë³´ë‹¤ í¬ë˜ì‹œ ì—†ëŠ” ì•ˆì •ì„±ì´ ë” ì¤‘ìš”
   - ì‚¬ìš©ì ê²½í—˜ ê´€ì ì—ì„œ ì ‘ê·¼

## ğŸ“… ì—…ë°ì´íŠ¸ ì´ë ¥
- 2024-12-29: ì´ˆê¸° ë¬¸ì„œ ì‘ì„±
- well ë¸Œëœì¹˜ ìƒì„± ë° ì•ˆì •í™” ì™„ë£Œ
- PyTorch native SDPA ê¸°ë°˜ êµ¬í˜„ í™•ì •

## ğŸ”— ê´€ë ¨ íŒŒì¼
- `/Wan2.2/wan/modules/attention.py` - ë©”ì¸ attention êµ¬í˜„
- `/Wan2.2/wan/configs/shared_config.py` - ì„¤ì • íŒŒì¼
- `/app/` - Electron ì•± ë””ë ‰í† ë¦¬

---

**Note**: ì´ êµ¬í˜„ì€ Windows 11 + RTX GPU í™˜ê²½ì—ì„œ ìµœì í™”ë˜ì—ˆìœ¼ë©°, ë‹¤ë¥¸ í™˜ê²½ì—ì„œëŠ” ì„±ëŠ¥ íŠ¹ì„±ì´ ë‹¤ë¥¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

======================+++++++++++++++++++++++++++=======================
ì‹¤ì œ ì‹¤í–‰ ë¡œê·¸ë‚´ìš© (5ì´ˆ, 24FPS, 50step,1280*504, TI2V-5B)

[info] Output will be saved to: D:\work\Artifex.AI\output\ìƒˆ í´ë”\q1.mp4
[2025-08-29 12:19:57,604] INFO: offload_model is not specified, set to True.
[2025-08-29 12:19:57,604] INFO: Generation job args: Namespace(task='ti2v-5B', size='1280*704', frame_num=121, ckpt_dir='D:\\work\\Artifex.AI\\Wan2.2-TI2V-5B', offload_model=True, ulysses_size=1, t5_fsdp=False, t5_cpu=False, dit_fsdp=False, save_file='D:\\work\\Artifex.AI\\output\\ìƒˆ í´ë”\\q1.mp4', prompt='A cinematic sunset over mountain lake', use_prompt_extend=False, prompt_extend_method='local_qwen', prompt_extend_model=None, prompt_extend_target_lang='zh', base_seed=7027874542372879868, image='E:\\StabilityMatrix\\Data\\Images\\Text2Img\\2025-06-12\\00110-2411132797.png', sample_solver='unipc', sample_steps=50, sample_shift=5.0, sample_guide_scale=5.0, convert_model_dtype=True, num_clip=None, audio=None, pose_video=None, start_from_ref=False, infer_frames=80)
[2025-08-29 12:19:57,604] INFO: Generation model config: {'__name__': 'Config: Wan TI2V 5B', 't5_model': 'umt5_xxl', 't5_dtype': torch.bfloat16, 'text_len': 512, 'param_dtype': torch.bfloat16, 'num_train_timesteps': 1000, 'sample_fps': 24, 'sample_neg_prompt': 'è‰²è°ƒè‰³ä¸½ï¼Œè¿‡æ›ï¼Œé™æ€ï¼Œç»†èŠ‚æ¨¡ç³Šä¸æ¸…ï¼Œå­—å¹•ï¼Œé£æ ¼ï¼Œä½œå“ï¼Œç”»ä½œï¼Œç”»é¢ï¼Œé™æ­¢ï¼Œæ•´ä½“å‘ç°ï¼Œæœ€å·®è´¨é‡ï¼Œä½è´¨é‡ï¼ŒJPEGå‹ç¼©æ®‹ç•™ï¼Œä¸‘é™‹çš„ï¼Œæ®‹ç¼ºçš„ï¼Œå¤šä½™çš„æ‰‹æŒ‡ï¼Œç”»å¾—ä¸å¥½çš„æ‰‹éƒ¨ï¼Œç”»å¾—ä¸å¥½çš„è„¸éƒ¨ï¼Œç•¸å½¢çš„ï¼Œæ¯å®¹çš„ï¼Œå½¢æ€ç•¸å½¢çš„è‚¢ä½“ï¼Œæ‰‹æŒ‡èåˆï¼Œé™æ­¢ä¸åŠ¨çš„ç”»é¢ï¼Œæ‚ä¹±çš„èƒŒæ™¯ï¼Œä¸‰æ¡è…¿ï¼ŒèƒŒæ™¯äººå¾ˆå¤šï¼Œå€’ç€èµ°', 'frame_num': 121, 't5_checkpoint': 'models_t5_umt5-xxl-enc-bf16.pth', 't5_tokenizer': 'google/umt5-xxl', 'vae_checkpoint': 'Wan2.2_VAE.pth', 'vae_stride': (4, 16, 16), 'patch_size': (1, 2, 2), 'dim': 3072, 'ffn_dim': 14336, 'freq_dim': 256, 'num_heads': 24, 'num_layers': 30, 'window_size': (-1, -1), 'qk_norm': True, 'cross_attn_norm': True, 'eps': 1e-06, 'sample_shift': 5.0, 'sample_steps': 50, 'sample_guide_scale': 5.0}
[2025-08-29 12:19:57,604] INFO: Input prompt: A cinematic sunset over mountain lake
[2025-08-29 12:19:57,627] INFO: Input image: E:\StabilityMatrix\Data\Images\Text2Img\2025-06-12\00110-2411132797.png
[2025-08-29 12:19:57,627] INFO: Creating WanTI2V pipeline.
[2025-08-29 12:20:56,699] INFO: loading D:\work\Artifex.AI\Wan2.2-TI2V-5B\models_t5_umt5-xxl-enc-bf16.pth
[2025-08-29 12:21:01,638] INFO: loading D:\work\Artifex.AI\Wan2.2-TI2V-5B\Wan2.2_VAE.pth
[2025-08-29 12:21:03,744] INFO: Creating WanModel from D:\work\Artifex.AI\Wan2.2-TI2V-5B

Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 37.14it/s]
[2025-08-29 12:21:03,962] WARNING: A matching Triton is not available, some optimizations will not be enabled
Traceback (most recent call last):
  File "C:\Users\choon\AppData\Local\Programs\Python\Python312\Lib\site-packages\xformers\__init__.py", line 57, in _is_triton_available
    import triton  # noqa
    ^^^^^^^^^^^^^
ModuleNotFoundError: No module named 'triton'
[2025-08-29 12:21:12,898] INFO: Generating video ...

  0%|          | 0/50 [00:00<?, ?it/s]
  2%|â–         | 1/50 [00:22<18:02, 22.08s/it]
  4%|â–         | 2/50 [00:43<17:35, 21.98s/it]
  6%|â–Œ         | 3/50 [01:06<17:22, 22.17s/it]
  8%|â–Š         | 4/50 [01:28<16:51, 21.99s/it]
 10%|â–ˆ         | 5/50 [01:50<16:28, 21.96s/it]
 12%|â–ˆâ–        | 6/50 [02:12<16:09, 22.04s/it]
 14%|â–ˆâ–        | 7/50 [02:34<15:47, 22.03s/it]
 16%|â–ˆâ–Œ        | 8/50 [02:59<16:12, 23.15s/it]
 18%|â–ˆâ–Š        | 9/50 [03:23<16:02, 23.49s/it]
 20%|â–ˆâ–ˆ        | 10/50 [03:46<15:22, 23.07s/it]
 22%|â–ˆâ–ˆâ–       | 11/50 [04:08<14:54, 22.93s/it]
 24%|â–ˆâ–ˆâ–       | 12/50 [04:50<18:11, 28.72s/it]
 26%|â–ˆâ–ˆâ–Œ       | 13/50 [05:26<18:57, 30.75s/it]
 28%|â–ˆâ–ˆâ–Š       | 14/50 [05:49<17:09, 28.59s/it]
 30%|â–ˆâ–ˆâ–ˆ       | 15/50 [06:14<16:05, 27.58s/it]
 32%|â–ˆâ–ˆâ–ˆâ–      | 16/50 [06:36<14:40, 25.90s/it]
 34%|â–ˆâ–ˆâ–ˆâ–      | 17/50 [07:49<21:54, 39.82s/it]
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 18/50 [08:16<19:11, 36.00s/it]
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 19/50 [08:39<16:40, 32.29s/it]
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 20/50 [09:07<15:25, 30.84s/it]
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/50 [09:43<15:44, 32.57s/it]
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 22/50 [10:07<13:56, 29.87s/it]
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 23/50 [10:30<12:34, 27.95s/it]
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 24/50 [10:52<11:19, 26.15s/it]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 25/50 [11:14<10:21, 24.84s/it]
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/50 [11:36<09:34, 23.94s/it]
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 27/50 [11:58<08:56, 23.33s/it]
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 28/50 [12:23<08:47, 23.97s/it]
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 29/50 [12:51<08:47, 25.10s/it]
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 30/50 [13:15<08:13, 24.67s/it]
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/50 [13:41<07:55, 25.04s/it]
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 32/50 [14:07<07:38, 25.45s/it]
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 33/50 [14:33<07:12, 25.41s/it]
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 34/50 [14:58<06:45, 25.37s/it]
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 35/50 [15:23<06:20, 25.36s/it]
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 36/50 [15:45<05:40, 24.29s/it]
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 37/50 [16:07<05:06, 23.56s/it]
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 38/50 [16:31<04:43, 23.63s/it]
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 39/50 [17:00<04:38, 25.36s/it]
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 40/50 [17:25<04:13, 25.34s/it]
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 41/50 [17:49<03:43, 24.80s/it]
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 42/50 [18:11<03:11, 23.97s/it]
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 43/50 [18:33<02:43, 23.34s/it]
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 44/50 [18:55<02:17, 22.89s/it]
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 45/50 [19:16<01:52, 22.58s/it]
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 46/50 [19:38<01:29, 22.35s/it]
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 47/50 [20:00<01:06, 22.19s/it]
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 48/50 [20:22<00:44, 22.07s/it]
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 49/50 [20:54<00:25, 25.06s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [21:20<00:00, 25.44s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [21:20<00:00, 25.61s/it]
[2025-08-29 12:50:14,691] INFO: Saving generated video to D:\work\Artifex.AI\output\ìƒˆ í´ë”\q1.mp4
[2025-08-29 12:50:16,534] INFO: [progress] saved=D:\work\Artifex.AI\output\ìƒˆ í´ë”\q1.mp4
[2025-08-29 12:50:16,535] INFO: Finished.

[closed] code=0
